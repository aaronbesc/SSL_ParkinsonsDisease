{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6abe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "# Load YOLO model\n",
    "model_yolo = YOLO('yolov8m-pose.pt')\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "output_file = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Lists to store tracked keypoint positions\n",
    "trackpoint1 = []\n",
    "trackpoint2 = []\n",
    "\n",
    "# Colors for each keypoint (in BGR format)\n",
    "color1 = (255, 0, 0)  # Blue\n",
    "color2 = (0, 255, 0)  # Green\n",
    "\n",
    "# Initialize variables for angle threshold tracking\n",
    "angle_threshold = 95\n",
    "below_threshold_count = 0\n",
    "prev_angle = None\n",
    "\n",
    "# Set up the matplotlib figure and subplots for real-time plotting (vertically stacked)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "lines1, = axes[0].plot([], [], 'b', label='X coordinates')\n",
    "lines1_y, = axes[0].plot([], [], 'r', label='Y coordinates')\n",
    "lines2, = axes[1].plot([], [], 'b', label='X coordinates')\n",
    "lines2_y, = axes[1].plot([], [], 'r', label='Y coordinates')\n",
    "\n",
    "axes[0].set_xlim(0, 1000)  # Set to the expected range of steps\n",
    "axes[0].set_ylim(0, frame_height)\n",
    "axes[0].set_title('Knee Coordinates vs Time Steps')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlim(0, 1000)\n",
    "axes[1].set_ylim(0, frame_height)\n",
    "axes[1].set_title('Hips Coordinates vs Time Steps')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Initialize step counter\n",
    "step = 0\n",
    "\n",
    "def calculate_angle(x1, y1, x2, y2):\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_radians = math.atan2(delta_y, delta_x)\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "    return abs(angle_degrees)\n",
    "\n",
    "def update_plot(i):\n",
    "    global step, below_threshold_count,  prev_angle\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Reached end of video.\")\n",
    "        return\n",
    "\n",
    "    # Perform YOLO detection\n",
    "    results = model_yolo(frame, stream=False, show=False)\n",
    "    for result in results:\n",
    "        keypoints = result.keypoints.xy  # Keypoints object for pose outputs\n",
    "        matrix = np.asarray(keypoints[0])\n",
    "\n",
    "        # Draw all keypoints on the frame\n",
    "        for point in matrix:\n",
    "            if not np.array_equal(point, [0, 0]):\n",
    "                cv2.circle(frame, (int(point[0]), int(point[1])), 3, (255, 255, 255), -1)  # White for all keypoints\n",
    "\n",
    "        # Ensure matrix has enough keypoints before accessing the desired keypoints\n",
    "        if len(matrix) > 16:\n",
    "            point1 = matrix[13]\n",
    "            point2 = matrix[11]\n",
    "            \n",
    "            if not np.array_equal(point1, [0, 0]):\n",
    "                trackpoint1.append((step, point1[0], point1[1]))\n",
    "            if not np.array_equal(point2, [0, 0]):\n",
    "                trackpoint2.append((step, point2[0], point2[1]))\n",
    "\n",
    "    # Draw colored dots and lines for each tracked keypoint\n",
    "    for i in range(1, len(trackpoint1)):\n",
    "        pt1 = (int(trackpoint1[i-1][1]), int(trackpoint1[i-1][2]))\n",
    "        pt2 = (int(trackpoint1[i][1]), int(trackpoint1[i][2]))\n",
    "        cv2.circle(frame, pt2, 3, color1, -1)  # Draw dot\n",
    "        cv2.line(frame, pt1, pt2, color1, 2)  # Draw line\n",
    "\n",
    "    for i in range(1, len(trackpoint2)):\n",
    "        pt1 = (int(trackpoint2[i-1][1]), int(trackpoint2[i-1][2]))\n",
    "        pt2 = (int(trackpoint2[i][1]), int(trackpoint2[i][2]))\n",
    "        cv2.circle(frame, pt2, 3, color2, -1)  # Draw dot\n",
    "        cv2.line(frame, pt1, pt2, color2, 2)  # Draw line\n",
    "\n",
    "    # Calculate the absolute angle between the two points\n",
    "    if len(trackpoint1) > 0 and len(trackpoint2) > 0:\n",
    "        x1, y1 = trackpoint1[-1][1], trackpoint1[-1][2]\n",
    "        x2, y2 = trackpoint2[-1][1], trackpoint2[-1][2]\n",
    "        angle = calculate_angle(x1, y1, x2, y2)\n",
    "\n",
    "        # Check for transition from high value to below threshold\n",
    "        if prev_angle is not None and prev_angle >= angle_threshold and angle < angle_threshold:\n",
    "            below_threshold_count += 1\n",
    "            below_threshold_start_time = None\n",
    "\n",
    "        # Update the previous angle\n",
    "        prev_angle = angle\n",
    "\n",
    "        # Display the angle and count\n",
    "        cv2.putText(frame, f\"Angle: {angle:.2f} degrees\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f\"Count: {below_threshold_count}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Save the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Update plots\n",
    "    if trackpoint1:\n",
    "        steps1, x_coords1, y_coords1 = zip(*trackpoint1)\n",
    "        lines1.set_data(steps1, x_coords1)\n",
    "        lines1_y.set_data(steps1, y_coords1)\n",
    "\n",
    "    if trackpoint2:\n",
    "        steps2, x_coords2, y_coords2 = zip(*trackpoint2)\n",
    "        lines2.set_data(steps2, x_coords2)\n",
    "        lines2_y.set_data(steps2, y_coords2)\n",
    "\n",
    "    # Display the frame with keypoints and connecting lines\n",
    "    cv2.imshow('Video1', frame)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        plt.close('all')\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "# Create the animation\n",
    "#ani = FuncAnimation(fig, update_plot, frames=range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), interval=10)\n",
    "ani = FuncAnimation(fig, update_plot, interval=10)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b81ea1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model_yolo = YOLO('yolov8m-pose.pt')\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "output_file = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Lists to store tracked keypoint positions\n",
    "trackpoint1 = []\n",
    "trackpoint2 = []\n",
    "\n",
    "# Colors for each keypoint (in BGR format)\n",
    "color1 = (255, 0, 0)  # Blue\n",
    "color2 = (0, 255, 0)  # Green\n",
    "\n",
    "# Initialize variables for angle threshold tracking\n",
    "angle_threshold = 90\n",
    "below_threshold_count = 0\n",
    "prev_angle = None\n",
    "\n",
    "# Set up the matplotlib figure and subplots for real-time plotting (vertically stacked)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "lines1, = axes[0].plot([], [], 'b', label='Knee X coordinates')\n",
    "lines1_y, = axes[0].plot([], [], 'r', label='Knee Y coordinates')\n",
    "lines2, = axes[1].plot([], [], 'b', label='Hips X coordinates')\n",
    "lines2_y, = axes[1].plot([], [], 'r', label='Hips Y coordinates')\n",
    "\n",
    "# Set up the plot axis limits\n",
    "axes[0].set_xlim(0, 1700)  # Set to the expected range of steps\n",
    "axes[0].set_ylim(0, frame_height)\n",
    "axes[0].set_title('Tracking Knee Coordinates vs Time Steps')\n",
    "axes[0].legend()  # Add legend to the first subplot\n",
    "\n",
    "axes[1].set_xlim(0, 1700)\n",
    "axes[1].set_ylim(0, frame_height)\n",
    "axes[1].set_title('Tracking Hips Coordinates vs Time Steps')\n",
    "axes[1].legend()  # Add legend to the second subplot\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Initialize step counter\n",
    "step = 0\n",
    "\n",
    "def calculate_angle(x1, y1, x2, y2):\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_radians = math.atan2(delta_y, delta_x)\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "    return abs(angle_degrees)\n",
    "\n",
    "def update_plot(i):\n",
    "    global step, below_threshold_count, prev_angle\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Reached end of video.\")\n",
    "        return\n",
    "\n",
    "    # Perform YOLO detection\n",
    "    results = model_yolo(frame, stream=False, show=False)\n",
    "    for result in results:\n",
    "        keypoints = result.keypoints.xy  # Keypoints object for pose outputs\n",
    "        matrix = np.asarray(keypoints[0])\n",
    "\n",
    "        # Draw all keypoints on the frame\n",
    "        for point in matrix:\n",
    "            if not np.array_equal(point, [0, 0]):\n",
    "                cv2.circle(frame, (int(point[0]), int(point[1])), 3, (255, 255, 255), -1)  # White for all keypoints\n",
    "\n",
    "        # Ensure matrix has enough keypoints before accessing the desired keypoints\n",
    "        if len(matrix) > 16:\n",
    "            point1 = matrix[13]\n",
    "            point2 = matrix[11]\n",
    "\n",
    "            if not np.array_equal(point1, [0, 0]):\n",
    "                trackpoint1.append((step, point1[0], point1[1]))\n",
    "            if not np.array_equal(point2, [0, 0]):\n",
    "                trackpoint2.append((step, point2[0], point2[1]))\n",
    "\n",
    "    # Draw colored dots and lines for each tracked keypoint\n",
    "    for i in range(1, len(trackpoint1)):\n",
    "        pt1 = (int(trackpoint1[i-1][1]), int(trackpoint1[i-1][2]))\n",
    "        pt2 = (int(trackpoint1[i][1]), int(trackpoint1[i][2]))\n",
    "        cv2.circle(frame, pt2, 3, color1, -1)  # Draw dot\n",
    "        cv2.line(frame, pt1, pt2, color1, 2)  # Draw line\n",
    "\n",
    "    for i in range(1, len(trackpoint2)):\n",
    "        pt1 = (int(trackpoint2[i-1][1]), int(trackpoint2[i-1][2]))\n",
    "        pt2 = (int(trackpoint2[i][1]), int(trackpoint2[i][2]))\n",
    "        cv2.circle(frame, pt2, 3, color2, -1)  # Draw dot\n",
    "        cv2.line(frame, pt1, pt2, color2, 2)  # Draw line\n",
    "\n",
    "    # Calculate the absolute angle between the two points\n",
    "    if len(trackpoint1) > 0 and len(trackpoint2) > 0:\n",
    "        x1, y1 = trackpoint1[-1][1], trackpoint1[-1][2]\n",
    "        x2, y2 = trackpoint2[-1][1], trackpoint2[-1][2]\n",
    "        angle = calculate_angle(x1, y1, x2, y2)\n",
    "\n",
    "        # Check for transition from high value to below threshold\n",
    "        if prev_angle is not None and prev_angle >= angle_threshold and angle < angle_threshold:\n",
    "            below_threshold_count += 1\n",
    "\n",
    "        # Update the previous angle\n",
    "        prev_angle = angle\n",
    "\n",
    "        # Display the angle and count\n",
    "        cv2.putText(frame, f\"Angle: {angle:.2f} degrees\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        #cv2.putText(frame, f\"Count: {below_threshold_count}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Save the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Update plots\n",
    "    if trackpoint1:\n",
    "        steps1, x_coords1, y_coords1 = zip(*trackpoint1)\n",
    "        lines1.set_data(steps1, x_coords1)\n",
    "        lines1_y.set_data(steps1, y_coords1)\n",
    "\n",
    "    if trackpoint2:\n",
    "        steps2, x_coords2, y_coords2 = zip(*trackpoint2)\n",
    "        lines2.set_data(steps2, x_coords2)\n",
    "        lines2_y.set_data(steps2, y_coords2)\n",
    "\n",
    "    # Display the frame with keypoints and connecting lines\n",
    "    resized_frame = cv2.resize(frame, (int(frame_width * 1.9 ), int(frame_height * 1.5)))\n",
    "    cv2.imshow('Video1', resized_frame)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        plt.close('all')\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update_plot, frames=range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), interval=10)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31a017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 174.0ms\n",
      "Speed: 2.2ms preprocess, 174.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 182.8ms\n",
      "Speed: 1.5ms preprocess, 182.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.9ms\n",
      "Speed: 1.2ms preprocess, 144.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.8ms\n",
      "Speed: 1.2ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.7ms\n",
      "Speed: 1.1ms preprocess, 158.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.4ms\n",
      "Speed: 1.1ms preprocess, 142.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.2ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.1ms preprocess, 147.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.2ms\n",
      "Speed: 1.1ms preprocess, 159.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Speed: 1.1ms preprocess, 147.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.1ms\n",
      "Speed: 1.2ms preprocess, 151.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.4ms\n",
      "Speed: 1.5ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.0ms\n",
      "Speed: 1.1ms preprocess, 155.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.2ms\n",
      "Speed: 1.0ms preprocess, 152.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.8ms\n",
      "Speed: 1.0ms preprocess, 143.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.0ms\n",
      "Speed: 17.7ms preprocess, 168.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.3ms\n",
      "Speed: 1.1ms preprocess, 154.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.4ms\n",
      "Speed: 1.1ms preprocess, 164.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 1.1ms preprocess, 143.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.3ms\n",
      "Speed: 1.1ms preprocess, 146.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.1ms preprocess, 149.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.0ms\n",
      "Speed: 1.1ms preprocess, 145.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Speed: 1.0ms preprocess, 146.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.1ms\n",
      "Speed: 1.1ms preprocess, 159.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.8ms\n",
      "Speed: 1.0ms preprocess, 159.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.3ms\n",
      "Speed: 1.2ms preprocess, 158.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.2ms\n",
      "Speed: 1.1ms preprocess, 157.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.7ms\n",
      "Speed: 1.1ms preprocess, 145.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.1ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.0ms\n",
      "Speed: 1.0ms preprocess, 146.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 172.1ms\n",
      "Speed: 1.3ms preprocess, 172.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.8ms\n",
      "Speed: 1.0ms preprocess, 155.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.0ms\n",
      "Speed: 1.2ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.0ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.9ms\n",
      "Speed: 1.1ms preprocess, 147.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.4ms\n",
      "Speed: 1.1ms preprocess, 155.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.4ms\n",
      "Speed: 1.1ms preprocess, 159.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.7ms\n",
      "Speed: 1.1ms preprocess, 154.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.1ms\n",
      "Speed: 1.1ms preprocess, 157.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.8ms\n",
      "Speed: 1.1ms preprocess, 162.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.5ms\n",
      "Speed: 1.1ms preprocess, 150.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.2ms\n",
      "Speed: 1.0ms preprocess, 151.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.9ms\n",
      "Speed: 1.1ms preprocess, 173.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.0ms\n",
      "Speed: 1.1ms preprocess, 153.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.1ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Speed: 1.1ms preprocess, 146.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 176.6ms\n",
      "Speed: 1.3ms preprocess, 176.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.0ms\n",
      "Speed: 1.2ms preprocess, 175.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.4ms\n",
      "Speed: 1.1ms preprocess, 148.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.1ms\n",
      "Speed: 1.1ms preprocess, 161.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 167.7ms\n",
      "Speed: 1.2ms preprocess, 167.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 170.2ms\n",
      "Speed: 1.2ms preprocess, 170.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.3ms\n",
      "Speed: 1.1ms preprocess, 161.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 169.9ms\n",
      "Speed: 1.1ms preprocess, 169.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 170.4ms\n",
      "Speed: 1.1ms preprocess, 170.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.1ms\n",
      "Speed: 1.5ms preprocess, 159.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.9ms\n",
      "Speed: 1.1ms preprocess, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.2ms\n",
      "Speed: 1.1ms preprocess, 149.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.7ms\n",
      "Speed: 1.1ms preprocess, 154.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.1ms\n",
      "Speed: 1.1ms preprocess, 160.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.0ms preprocess, 147.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.1ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.1ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 1.3ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 1.1ms preprocess, 147.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.1ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.1ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.1ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.1ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.1ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.0ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.1ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.9ms\n",
      "Speed: 1.0ms preprocess, 140.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.0ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.0ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.4ms\n",
      "Speed: 1.1ms preprocess, 148.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.6ms\n",
      "Speed: 1.1ms preprocess, 141.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.9ms\n",
      "Speed: 1.1ms preprocess, 151.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.0ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 1.1ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.5ms\n",
      "Speed: 1.0ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 1.1ms preprocess, 144.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.0ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.1ms preprocess, 144.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.5ms\n",
      "Speed: 1.1ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.0ms\n",
      "Speed: 1.1ms preprocess, 149.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.1ms\n",
      "Speed: 1.0ms preprocess, 141.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.3ms\n",
      "Speed: 1.1ms preprocess, 163.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.0ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.1ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.1ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.1ms\n",
      "Speed: 1.1ms preprocess, 145.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.2ms\n",
      "Speed: 1.0ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.1ms\n",
      "Speed: 1.1ms preprocess, 145.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.0ms preprocess, 144.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.1ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.0ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.0ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.1ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.1ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 1.1ms preprocess, 144.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 1.1ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.1ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.0ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 1.1ms preprocess, 144.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 1.1ms preprocess, 144.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.1ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.1ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 1.1ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 1.1ms preprocess, 144.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.4ms\n",
      "Speed: 1.0ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.5ms\n",
      "Speed: 1.1ms preprocess, 141.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.0ms preprocess, 147.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.7ms\n",
      "Speed: 1.1ms preprocess, 146.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 1.1ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.1ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.4ms\n",
      "Speed: 1.1ms preprocess, 141.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.1ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.4ms\n",
      "Speed: 1.1ms preprocess, 149.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.5ms\n",
      "Speed: 1.2ms preprocess, 173.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.2ms\n",
      "Speed: 1.1ms preprocess, 175.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 1.1ms preprocess, 143.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.7ms\n",
      "Speed: 1.1ms preprocess, 166.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.8ms\n",
      "Speed: 1.1ms preprocess, 162.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 181.0ms\n",
      "Speed: 1.1ms preprocess, 181.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.6ms\n",
      "Speed: 1.1ms preprocess, 154.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.6ms\n",
      "Speed: 1.1ms preprocess, 162.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.8ms\n",
      "Speed: 1.1ms preprocess, 165.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.8ms\n",
      "Speed: 1.2ms preprocess, 157.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.8ms\n",
      "Speed: 1.1ms preprocess, 160.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.7ms\n",
      "Speed: 1.1ms preprocess, 163.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.9ms\n",
      "Speed: 1.1ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.3ms\n",
      "Speed: 1.1ms preprocess, 155.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.2ms\n",
      "Speed: 1.1ms preprocess, 154.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.0ms\n",
      "Speed: 1.1ms preprocess, 164.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.6ms\n",
      "Speed: 1.3ms preprocess, 162.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 1.2ms preprocess, 147.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.1ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.1ms\n",
      "Speed: 1.1ms preprocess, 141.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.0ms\n",
      "Speed: 1.3ms preprocess, 148.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.2ms\n",
      "Speed: 1.0ms preprocess, 161.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.1ms preprocess, 144.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 1.1ms preprocess, 143.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 1.1ms preprocess, 144.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.0ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.1ms preprocess, 142.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.0ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.6ms\n",
      "Speed: 1.1ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.1ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.1ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.8ms\n",
      "Speed: 0.9ms preprocess, 141.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.0ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.4ms\n",
      "Speed: 1.1ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.8ms\n",
      "Speed: 1.1ms preprocess, 162.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.1ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.1ms preprocess, 144.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.1ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.1ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 0.9ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.4ms\n",
      "Speed: 1.0ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.0ms\n",
      "Speed: 1.0ms preprocess, 146.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.3ms\n",
      "Speed: 1.0ms preprocess, 142.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 1.1ms preprocess, 144.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.0ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.3ms\n",
      "Speed: 1.0ms preprocess, 141.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.1ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.2ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.0ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.9ms\n",
      "Speed: 1.1ms preprocess, 146.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 1.1ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.0ms\n",
      "Speed: 1.0ms preprocess, 154.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.8ms\n",
      "Speed: 1.0ms preprocess, 141.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.1ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.4ms\n",
      "Speed: 1.1ms preprocess, 142.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.7ms\n",
      "Speed: 1.1ms preprocess, 141.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.3ms preprocess, 147.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 1.0ms preprocess, 143.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.4ms\n",
      "Speed: 1.1ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.0ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.5ms\n",
      "Speed: 1.0ms preprocess, 141.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.1ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.1ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.0ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.2ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.8ms\n",
      "Speed: 1.1ms preprocess, 141.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.1ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 148.1ms\n",
      "Speed: 1.2ms preprocess, 148.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 143.4ms\n",
      "Speed: 1.1ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.7ms\n",
      "Speed: 1.1ms preprocess, 141.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 142.3ms\n",
      "Speed: 1.1ms preprocess, 142.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 143.3ms\n",
      "Speed: 1.0ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 143.7ms\n",
      "Speed: 1.0ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.6ms\n",
      "Speed: 1.0ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.0ms\n",
      "Speed: 1.1ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.2ms\n",
      "Speed: 1.0ms preprocess, 165.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.2ms\n",
      "Speed: 1.1ms preprocess, 156.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.9ms\n",
      "Speed: 1.0ms preprocess, 153.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.3ms\n",
      "Speed: 1.1ms preprocess, 153.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.1ms\n",
      "Speed: 1.0ms preprocess, 175.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.2ms\n",
      "Speed: 1.0ms preprocess, 159.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.8ms\n",
      "Speed: 1.2ms preprocess, 159.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.7ms\n",
      "Speed: 1.1ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 1.0ms preprocess, 170.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.4ms\n",
      "Speed: 1.0ms preprocess, 154.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.0ms\n",
      "Speed: 1.0ms preprocess, 162.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.6ms\n",
      "Speed: 1.1ms preprocess, 165.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 222.1ms\n",
      "Speed: 1.1ms preprocess, 222.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 179.2ms\n",
      "Speed: 1.1ms preprocess, 179.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 183.4ms\n",
      "Speed: 1.1ms preprocess, 183.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 180.4ms\n",
      "Speed: 1.2ms preprocess, 180.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 1.0ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.3ms\n",
      "Speed: 1.1ms preprocess, 145.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.1ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 1.0ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.1ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.3ms\n",
      "Speed: 1.1ms preprocess, 146.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.0ms preprocess, 142.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.1ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.5ms\n",
      "Speed: 1.1ms preprocess, 147.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.4ms\n",
      "Speed: 1.1ms preprocess, 145.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 1.1ms preprocess, 144.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.5ms\n",
      "Speed: 1.1ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.4ms\n",
      "Speed: 1.0ms preprocess, 145.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.2ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.1ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.0ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 1.0ms preprocess, 144.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.0ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.4ms\n",
      "Speed: 1.1ms preprocess, 145.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.0ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.5ms\n",
      "Speed: 1.0ms preprocess, 146.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.0ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 1.0ms preprocess, 144.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.4ms\n",
      "Speed: 0.9ms preprocess, 141.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.0ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 1.1ms preprocess, 144.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Speed: 1.1ms preprocess, 146.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 1.0ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.3ms\n",
      "Speed: 1.3ms preprocess, 146.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.1ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.0ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.1ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.3ms\n",
      "Speed: 1.0ms preprocess, 142.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 1.1ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.6ms\n",
      "Speed: 1.0ms preprocess, 157.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 1.1ms preprocess, 144.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.5ms\n",
      "Speed: 1.2ms preprocess, 145.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 1.0ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.1ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.0ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.0ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 145.0ms\n",
      "Speed: 0.9ms preprocess, 145.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.4ms\n",
      "Speed: 1.0ms preprocess, 142.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.2ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.2ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.1ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.0ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.0ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.9ms\n",
      "Speed: 1.1ms preprocess, 148.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 1.1ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 1.1ms preprocess, 143.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.1ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.6ms\n",
      "Speed: 1.0ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.7ms\n",
      "Speed: 1.2ms preprocess, 141.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.0ms\n",
      "Speed: 1.1ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.0ms\n",
      "Speed: 1.2ms preprocess, 165.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.0ms\n",
      "Speed: 1.1ms preprocess, 153.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.0ms preprocess, 149.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.5ms\n",
      "Speed: 1.1ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.8ms\n",
      "Speed: 1.2ms preprocess, 159.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.6ms\n",
      "Speed: 1.1ms preprocess, 159.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 169.9ms\n",
      "Speed: 1.6ms preprocess, 169.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.0ms\n",
      "Speed: 1.1ms preprocess, 162.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.6ms\n",
      "Speed: 1.1ms preprocess, 159.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.7ms\n",
      "Speed: 1.1ms preprocess, 149.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 188.2ms\n",
      "Speed: 1.2ms preprocess, 188.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Speed: 1.2ms preprocess, 161.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.9ms\n",
      "Speed: 1.2ms preprocess, 156.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.4ms\n",
      "Speed: 1.2ms preprocess, 168.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.1ms\n",
      "Speed: 1.3ms preprocess, 160.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.5ms\n",
      "Speed: 1.1ms preprocess, 152.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.1ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.2ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.1ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.1ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.9ms\n",
      "Speed: 1.0ms preprocess, 145.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.0ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.8ms\n",
      "Speed: 1.0ms preprocess, 143.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 1.1ms preprocess, 144.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 1.1ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.9ms\n",
      "Speed: 1.0ms preprocess, 144.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.4ms\n",
      "Speed: 1.1ms preprocess, 142.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.5ms\n",
      "Speed: 1.0ms preprocess, 145.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 1.1ms preprocess, 144.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.2ms\n",
      "Speed: 1.2ms preprocess, 145.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.1ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 1.1ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.8ms\n",
      "Speed: 1.2ms preprocess, 141.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 1.1ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.5ms\n",
      "Speed: 1.0ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 1.1ms preprocess, 144.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.0ms preprocess, 144.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.4ms\n",
      "Speed: 1.0ms preprocess, 159.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.1ms\n",
      "Speed: 1.2ms preprocess, 158.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Speed: 1.1ms preprocess, 161.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.8ms\n",
      "Speed: 1.3ms preprocess, 150.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Speed: 1.1ms preprocess, 147.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.8ms\n",
      "Speed: 1.1ms preprocess, 145.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 1.1ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.8ms\n",
      "Speed: 1.0ms preprocess, 143.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.3ms\n",
      "Speed: 1.1ms preprocess, 145.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.5ms\n",
      "Speed: 1.3ms preprocess, 155.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 1.1ms preprocess, 144.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 person, 639.3ms\n",
      "Speed: 0.0ms preprocess, 639.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.5ms\n",
      "Speed: 0.0ms preprocess, 629.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.5ms\n",
      "Speed: 0.0ms preprocess, 629.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.8ms\n",
      "Speed: 0.0ms preprocess, 629.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 644.9ms\n",
      "Speed: 0.0ms preprocess, 644.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 661.2ms\n",
      "Speed: 0.0ms preprocess, 661.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.4ms\n",
      "Speed: 0.0ms preprocess, 630.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.6ms\n",
      "Speed: 0.0ms preprocess, 629.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 645.9ms\n",
      "Speed: 0.0ms preprocess, 645.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.4ms\n",
      "Speed: 0.0ms preprocess, 629.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.8ms\n",
      "Speed: 0.0ms preprocess, 629.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.8ms\n",
      "Speed: 0.0ms preprocess, 629.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 645.2ms\n",
      "Speed: 0.0ms preprocess, 645.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.4ms\n",
      "Speed: 0.0ms preprocess, 630.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 646.0ms\n",
      "Speed: 0.0ms preprocess, 646.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 636.2ms\n",
      "Speed: 8.6ms preprocess, 636.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.3ms\n",
      "Speed: 0.0ms preprocess, 630.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 638.9ms\n",
      "Speed: 7.1ms preprocess, 638.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 645.6ms\n",
      "Speed: 0.0ms preprocess, 645.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.2ms\n",
      "Speed: 0.0ms preprocess, 630.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.0ms\n",
      "Speed: 0.0ms preprocess, 630.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.1ms\n",
      "Speed: 0.0ms preprocess, 629.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 645.2ms\n",
      "Speed: 0.0ms preprocess, 645.2ms inference, 15.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 640.2ms\n",
      "Speed: 0.0ms preprocess, 640.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 651.3ms\n",
      "Speed: 10.0ms preprocess, 651.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.6ms\n",
      "Speed: 0.0ms preprocess, 630.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.4ms\n",
      "Speed: 0.0ms preprocess, 630.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 646.2ms\n",
      "Speed: 0.0ms preprocess, 646.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 634.6ms\n",
      "Speed: 0.0ms preprocess, 634.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 642.0ms\n",
      "Speed: 0.0ms preprocess, 642.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 630.0ms\n",
      "Speed: 0.0ms preprocess, 630.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.1ms\n",
      "Speed: 0.0ms preprocess, 629.1ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.8ms\n",
      "Speed: 0.0ms preprocess, 629.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.6ms\n",
      "Speed: 0.0ms preprocess, 629.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 646.1ms\n",
      "Speed: 0.0ms preprocess, 646.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 651.9ms\n",
      "Speed: 0.0ms preprocess, 651.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.2ms\n",
      "Speed: 0.0ms preprocess, 629.2ms inference, 15.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.4ms\n",
      "Speed: 0.0ms preprocess, 629.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 628.8ms\n",
      "Speed: 0.0ms preprocess, 628.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 629.8ms\n",
      "Speed: 0.0ms preprocess, 629.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 636.0ms\n",
      "Speed: 0.0ms preprocess, 636.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model_yolo = YOLO('yolov8m-pose.pt')\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "output_file = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Initialize variables for angle threshold tracking\n",
    "angle_threshold = 95\n",
    "below_threshold_count = 0\n",
    "prev_angle = None\n",
    "\n",
    "# Lists to store tracked keypoint positions\n",
    "trackpoint1 = []\n",
    "trackpoint2 = []\n",
    "\n",
    "# Colors for each keypoint (in BGR format)\n",
    "color1 = (255, 0, 0)  # Blue\n",
    "color2 = (0, 255, 0)  # Green\n",
    "\n",
    "def calculate_angle(x1, y1, x2, y2):\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_radians = math.atan2(delta_y, delta_x)\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "    return abs(angle_degrees)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Reached end of video.\")\n",
    "        break\n",
    "\n",
    "    # Perform YOLO detection\n",
    "    results = model_yolo(frame, stream=False, show=False)\n",
    "    for result in results:\n",
    "        keypoints = result.keypoints.xy  # Keypoints object for pose outputs\n",
    "        matrix = np.asarray(keypoints[0])\n",
    "\n",
    "        # Draw all keypoints on the frame\n",
    "        for point in matrix:\n",
    "            if not np.array_equal(point, [0, 0]):\n",
    "                cv2.circle(frame, (int(point[0]), int(point[1])), 3, (255, 255, 255), -1)  # White for all keypoints\n",
    "\n",
    "        # Ensure matrix has enough keypoints before accessing the desired keypoints\n",
    "        if len(matrix) > 16:\n",
    "            point1 = matrix[13]\n",
    "            point2 = matrix[11]\n",
    "\n",
    "            if not np.array_equal(point1, [0, 0]):\n",
    "                trackpoint1.append((len(trackpoint1), point1[0], point1[1]))\n",
    "            if not np.array_equal(point2, [0, 0]):\n",
    "                trackpoint2.append((len(trackpoint2), point2[0], point2[1]))\n",
    "\n",
    "    # Draw colored dots and lines for each tracked keypoint\n",
    "    for i in range(1, len(trackpoint1)):\n",
    "        pt1 = (int(trackpoint1[i-1][1]), int(trackpoint1[i-1][2]))\n",
    "        pt2 = (int(trackpoint1[i][1]), int(trackpoint1[i][2]))\n",
    "        cv2.circle(frame, pt2, 3, color1, -1)  # Draw dot\n",
    "        cv2.line(frame, pt1, pt2, color1, 2)  # Draw line\n",
    "\n",
    "    for i in range(1, len(trackpoint2)):\n",
    "        pt1 = (int(trackpoint2[i-1][1]), int(trackpoint2[i-1][2]))\n",
    "        pt2 = (int(trackpoint2[i][1]), int(trackpoint2[i][2]))\n",
    "        cv2.circle(frame, pt2, 3, color2, -1)  # Draw dot\n",
    "        cv2.line(frame, pt1, pt2, color2, 2)  # Draw line\n",
    "\n",
    "    # Calculate the absolute angle between the two points\n",
    "    if len(trackpoint1) > 0 and len(trackpoint2) > 0:\n",
    "        x1, y1 = trackpoint1[-1][1], trackpoint1[-1][2]\n",
    "        x2, y2 = trackpoint2[-1][1], trackpoint2[-1][2]\n",
    "        angle = calculate_angle(x1, y1, x2, y2)\n",
    "\n",
    "        # Check for transition from high value to below threshold\n",
    "        if prev_angle is not None and prev_angle >= angle_threshold and angle < angle_threshold:\n",
    "            below_threshold_count += 1\n",
    "\n",
    "        # Update the previous angle\n",
    "        prev_angle = angle\n",
    "\n",
    "        # Display the angle and count\n",
    "        cv2.putText(frame, f\"Angle: {angle:.2f} degrees\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f\"Count: {below_threshold_count}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Resize the frame to increase display size\n",
    "    resized_frame = cv2.resize(frame, (int(frame_width * 1.5), int(frame_height * 1.5)))\n",
    "\n",
    "    # Display the frame with keypoints and connecting lines\n",
    "    cv2.imshow('Video1', resized_frame)\n",
    "\n",
    "    # Save the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb9a12",
   "metadata": {},
   "source": [
    "### angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cefabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter.forcha\\AppData\\Local\\Temp\\ipykernel_24560\\2050747071.py:189: UserWarning: frames=None which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
      "  ani = FuncAnimation(fig, update_plot, interval=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 175.2ms\n",
      "Speed: 2.6ms preprocess, 175.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.3ms\n",
      "Speed: 1.7ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.2ms\n",
      "Speed: 1.2ms preprocess, 152.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.9ms\n",
      "Speed: 1.2ms preprocess, 155.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 1.0ms preprocess, 154.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.2ms\n",
      "Speed: 1.0ms preprocess, 152.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.9ms\n",
      "Speed: 0.9ms preprocess, 162.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.4ms\n",
      "Speed: 1.1ms preprocess, 163.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.9ms\n",
      "Speed: 1.1ms preprocess, 166.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 187.5ms\n",
      "Speed: 1.0ms preprocess, 187.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.3ms\n",
      "Speed: 1.0ms preprocess, 154.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.8ms\n",
      "Speed: 1.2ms preprocess, 159.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.2ms\n",
      "Speed: 1.0ms preprocess, 160.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.6ms\n",
      "Speed: 1.0ms preprocess, 152.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.7ms\n",
      "Speed: 1.2ms preprocess, 156.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.6ms\n",
      "Speed: 1.1ms preprocess, 152.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.5ms\n",
      "Speed: 0.9ms preprocess, 155.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.3ms\n",
      "Speed: 1.0ms preprocess, 163.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 1.1ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 171.7ms\n",
      "Speed: 1.0ms preprocess, 171.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 0.9ms preprocess, 152.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.0ms\n",
      "Speed: 1.0ms preprocess, 148.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.9ms\n",
      "Speed: 0.9ms preprocess, 158.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Speed: 1.0ms preprocess, 146.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 0.9ms preprocess, 144.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 1.1ms preprocess, 154.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 1.0ms preprocess, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.0ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.3ms\n",
      "Speed: 1.2ms preprocess, 150.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.4ms\n",
      "Speed: 1.0ms preprocess, 147.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.9ms\n",
      "Speed: 1.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.3ms\n",
      "Speed: 1.0ms preprocess, 150.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Speed: 1.0ms preprocess, 145.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.0ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.6ms\n",
      "Speed: 1.0ms preprocess, 160.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 1.0ms preprocess, 144.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 183.2ms\n",
      "Speed: 0.9ms preprocess, 183.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.4ms\n",
      "Speed: 1.1ms preprocess, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.5ms\n",
      "Speed: 0.9ms preprocess, 147.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.0ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.1ms preprocess, 149.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.1ms\n",
      "Speed: 1.3ms preprocess, 147.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 1.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 192.8ms\n",
      "Speed: 1.2ms preprocess, 192.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 186.8ms\n",
      "Speed: 1.1ms preprocess, 186.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.8ms\n",
      "Speed: 1.1ms preprocess, 159.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.0ms\n",
      "Speed: 1.1ms preprocess, 173.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 193.9ms\n",
      "Speed: 1.1ms preprocess, 193.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 179.2ms\n",
      "Speed: 1.0ms preprocess, 179.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.5ms\n",
      "Speed: 1.2ms preprocess, 166.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.3ms\n",
      "Speed: 1.2ms preprocess, 157.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 191.1ms\n",
      "Speed: 1.1ms preprocess, 191.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 180.1ms\n",
      "Speed: 1.1ms preprocess, 180.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.1ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.3ms\n",
      "Speed: 1.1ms preprocess, 150.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.8ms\n",
      "Speed: 1.1ms preprocess, 143.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 0.9ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.1ms preprocess, 149.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.5ms\n",
      "Speed: 1.0ms preprocess, 145.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.9ms\n",
      "Speed: 1.1ms preprocess, 144.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.2ms\n",
      "Speed: 1.2ms preprocess, 151.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.6ms\n",
      "Speed: 1.0ms preprocess, 146.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.0ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Speed: 1.2ms preprocess, 146.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 178.1ms\n",
      "Speed: 1.0ms preprocess, 178.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.5ms\n",
      "Speed: 1.1ms preprocess, 147.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.2ms\n",
      "Speed: 1.3ms preprocess, 162.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.0ms\n",
      "Speed: 1.0ms preprocess, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.5ms\n",
      "Speed: 1.0ms preprocess, 144.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.0ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 1.1ms preprocess, 148.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.6ms\n",
      "Speed: 1.0ms preprocess, 150.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.7ms\n",
      "Speed: 1.0ms preprocess, 145.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Speed: 1.2ms preprocess, 147.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.1ms\n",
      "Speed: 1.0ms preprocess, 146.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 0.9ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.6ms\n",
      "Speed: 1.3ms preprocess, 159.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 1.0ms preprocess, 148.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.0ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.3ms\n",
      "Speed: 1.1ms preprocess, 145.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 179.6ms\n",
      "Speed: 1.1ms preprocess, 179.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 0.9ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 1.1ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.9ms\n",
      "Speed: 1.0ms preprocess, 151.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 1.0ms preprocess, 144.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.1ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.7ms\n",
      "Speed: 1.1ms preprocess, 151.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 1.0ms preprocess, 144.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 1.2ms preprocess, 143.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.9ms\n",
      "Speed: 1.1ms preprocess, 151.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.9ms\n",
      "Speed: 1.0ms preprocess, 145.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.6ms\n",
      "Speed: 0.9ms preprocess, 141.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.6ms\n",
      "Speed: 1.2ms preprocess, 153.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.3ms\n",
      "Speed: 0.9ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 1.0ms preprocess, 143.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.7ms\n",
      "Speed: 1.1ms preprocess, 148.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.2ms\n",
      "Speed: 0.9ms preprocess, 158.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.9ms\n",
      "Speed: 1.0ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.4ms\n",
      "Speed: 1.1ms preprocess, 147.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.4ms\n",
      "Speed: 1.0ms preprocess, 157.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.4ms\n",
      "Speed: 1.0ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.5ms\n",
      "Speed: 1.1ms preprocess, 147.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Speed: 1.0ms preprocess, 147.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.0ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.8ms\n",
      "Speed: 1.3ms preprocess, 148.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.1ms\n",
      "Speed: 0.9ms preprocess, 202.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 178.1ms\n",
      "Speed: 1.1ms preprocess, 178.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.2ms\n",
      "Speed: 1.1ms preprocess, 155.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 167.4ms\n",
      "Speed: 1.1ms preprocess, 167.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 196.3ms\n",
      "Speed: 1.1ms preprocess, 196.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 185.7ms\n",
      "Speed: 1.2ms preprocess, 185.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.2ms\n",
      "Speed: 1.0ms preprocess, 175.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.2ms\n",
      "Speed: 1.2ms preprocess, 149.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 179.6ms\n",
      "Speed: 1.0ms preprocess, 179.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 207.3ms\n",
      "Speed: 1.2ms preprocess, 207.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.8ms\n",
      "Speed: 1.5ms preprocess, 151.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.7ms\n",
      "Speed: 1.1ms preprocess, 141.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.5ms\n",
      "Speed: 1.0ms preprocess, 150.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.1ms\n",
      "Speed: 1.0ms preprocess, 149.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.2ms\n",
      "Speed: 1.0ms preprocess, 146.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.2ms preprocess, 149.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.1ms\n",
      "Speed: 1.0ms preprocess, 146.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.1ms preprocess, 147.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.8ms\n",
      "Speed: 1.1ms preprocess, 148.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 1.1ms preprocess, 154.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 1.0ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.1ms\n",
      "Speed: 1.1ms preprocess, 148.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.9ms\n",
      "Speed: 1.0ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.6ms\n",
      "Speed: 1.0ms preprocess, 141.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 1.2ms preprocess, 144.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 176.7ms\n",
      "Speed: 1.0ms preprocess, 176.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 1.0ms preprocess, 147.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.6ms\n",
      "Speed: 1.0ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.0ms\n",
      "Speed: 1.1ms preprocess, 151.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.5ms\n",
      "Speed: 1.0ms preprocess, 149.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 0.9ms preprocess, 143.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.1ms\n",
      "Speed: 1.3ms preprocess, 163.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.4ms\n",
      "Speed: 1.2ms preprocess, 149.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Speed: 1.1ms preprocess, 145.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.5ms\n",
      "Speed: 1.1ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.6ms\n",
      "Speed: 1.0ms preprocess, 150.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.5ms\n",
      "Speed: 1.0ms preprocess, 150.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.1ms\n",
      "Speed: 1.1ms preprocess, 159.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Speed: 1.1ms preprocess, 161.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.8ms\n",
      "Speed: 1.0ms preprocess, 152.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 1.0ms preprocess, 144.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.4ms\n",
      "Speed: 1.1ms preprocess, 150.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.9ms\n",
      "Speed: 0.9ms preprocess, 155.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.9ms\n",
      "Speed: 1.2ms preprocess, 144.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.7ms\n",
      "Speed: 1.3ms preprocess, 145.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.1ms\n",
      "Speed: 1.0ms preprocess, 166.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.0ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 1.2ms preprocess, 148.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.6ms\n",
      "Speed: 0.9ms preprocess, 152.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.3ms\n",
      "Speed: 1.0ms preprocess, 146.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 0.9ms preprocess, 144.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.3ms\n",
      "Speed: 1.2ms preprocess, 149.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 1.0ms preprocess, 147.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 1.0ms preprocess, 143.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.5ms\n",
      "Speed: 1.0ms preprocess, 165.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 1.1ms preprocess, 154.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.6ms\n",
      "Speed: 1.0ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 1.2ms preprocess, 147.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.1ms\n",
      "Speed: 1.0ms preprocess, 153.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.1ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.2ms\n",
      "Speed: 1.2ms preprocess, 148.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.8ms\n",
      "Speed: 1.1ms preprocess, 158.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.1ms\n",
      "Speed: 1.1ms preprocess, 173.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 159.1ms\n",
      "Speed: 1.1ms preprocess, 159.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 177.0ms\n",
      "Speed: 1.1ms preprocess, 177.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 183.0ms\n",
      "Speed: 1.1ms preprocess, 183.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 177.3ms\n",
      "Speed: 1.1ms preprocess, 177.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 180.6ms\n",
      "Speed: 1.2ms preprocess, 180.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 171.5ms\n",
      "Speed: 1.5ms preprocess, 171.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 182.9ms\n",
      "Speed: 1.0ms preprocess, 182.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 187.6ms\n",
      "Speed: 1.1ms preprocess, 187.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.7ms\n",
      "Speed: 1.2ms preprocess, 163.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.1ms\n",
      "Speed: 0.9ms preprocess, 147.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.0ms\n",
      "Speed: 1.1ms preprocess, 157.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.2ms\n",
      "Speed: 1.0ms preprocess, 146.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.8ms\n",
      "Speed: 1.3ms preprocess, 147.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.6ms\n",
      "Speed: 1.0ms preprocess, 150.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.1ms preprocess, 149.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.9ms\n",
      "Speed: 1.2ms preprocess, 164.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.9ms\n",
      "Speed: 1.0ms preprocess, 150.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.2ms\n",
      "Speed: 1.0ms preprocess, 147.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.9ms\n",
      "Speed: 1.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 1.3ms preprocess, 152.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.9ms\n",
      "Speed: 1.1ms preprocess, 154.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.7ms\n",
      "Speed: 1.1ms preprocess, 148.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.7ms\n",
      "Speed: 1.1ms preprocess, 158.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.6ms\n",
      "Speed: 0.9ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.8ms\n",
      "Speed: 1.1ms preprocess, 145.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.8ms\n",
      "Speed: 0.9ms preprocess, 156.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.9ms\n",
      "Speed: 1.1ms preprocess, 161.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.0ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.1ms\n",
      "Speed: 1.2ms preprocess, 162.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.0ms\n",
      "Speed: 1.1ms preprocess, 151.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 1.0ms preprocess, 143.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.4ms\n",
      "Speed: 1.2ms preprocess, 148.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.4ms\n",
      "Speed: 1.1ms preprocess, 158.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.2ms\n",
      "Speed: 1.1ms preprocess, 146.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 1.1ms preprocess, 148.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.4ms\n",
      "Speed: 1.0ms preprocess, 153.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 0.9ms preprocess, 143.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.8ms\n",
      "Speed: 1.2ms preprocess, 141.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.5ms\n",
      "Speed: 1.0ms preprocess, 151.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Speed: 1.0ms preprocess, 146.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 0.9ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.7ms\n",
      "Speed: 1.1ms preprocess, 151.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.7ms\n",
      "Speed: 1.0ms preprocess, 145.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.0ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.5ms\n",
      "Speed: 1.1ms preprocess, 151.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.3ms\n",
      "Speed: 1.0ms preprocess, 151.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.9ms\n",
      "Speed: 1.0ms preprocess, 143.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.3ms\n",
      "Speed: 1.2ms preprocess, 150.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.9ms\n",
      "Speed: 1.2ms preprocess, 147.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.0ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.3ms\n",
      "Speed: 1.2ms preprocess, 147.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.2ms\n",
      "Speed: 1.0ms preprocess, 150.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.0ms\n",
      "Speed: 1.0ms preprocess, 142.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Speed: 1.3ms preprocess, 145.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.8ms\n",
      "Speed: 1.0ms preprocess, 152.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 1.0ms preprocess, 142.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.9ms\n",
      "Speed: 1.2ms preprocess, 161.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.5ms\n",
      "Speed: 1.0ms preprocess, 153.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 187.3ms\n",
      "Speed: 1.2ms preprocess, 187.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.0ms\n",
      "Speed: 1.2ms preprocess, 160.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 160.3ms\n",
      "Speed: 1.3ms preprocess, 160.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 188.5ms\n",
      "Speed: 1.1ms preprocess, 188.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 197.1ms\n",
      "Speed: 1.5ms preprocess, 197.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 171.0ms\n",
      "Speed: 1.2ms preprocess, 171.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.3ms\n",
      "Speed: 1.2ms preprocess, 168.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.3ms\n",
      "Speed: 1.4ms preprocess, 173.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.4ms\n",
      "Speed: 1.2ms preprocess, 213.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 191.2ms\n",
      "Speed: 1.2ms preprocess, 191.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.4ms\n",
      "Speed: 1.3ms preprocess, 156.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.5ms\n",
      "Speed: 1.0ms preprocess, 146.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.2ms\n",
      "Speed: 1.2ms preprocess, 151.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.6ms\n",
      "Speed: 1.2ms preprocess, 149.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.9ms\n",
      "Speed: 1.1ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.0ms\n",
      "Speed: 1.2ms preprocess, 148.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.3ms\n",
      "Speed: 1.0ms preprocess, 149.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.5ms\n",
      "Speed: 1.0ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.8ms\n",
      "Speed: 1.1ms preprocess, 153.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.8ms\n",
      "Speed: 1.0ms preprocess, 148.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\knowledge_induced_noise\\Lib\\site-packages\\matplotlib\\backend_bases.py:1152\u001b[39m, in \u001b[36mTimerBase._on_timer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1146\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1147\u001b[39m \u001b[33;03mRuns all function that have been registered as callbacks. Functions\u001b[39;00m\n\u001b[32m   1148\u001b[39m \u001b[33;03mcan return False (or 0) if they should not be called any more. If there\u001b[39;00m\n\u001b[32m   1149\u001b[39m \u001b[33;03mare no callbacks, the timer is automatically stopped.\u001b[39;00m\n\u001b[32m   1150\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1151\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     ret = func(*args, **kwargs)\n\u001b[32m   1153\u001b[39m     \u001b[38;5;66;03m# docstring above explains why we use `if ret == 0` here,\u001b[39;00m\n\u001b[32m   1154\u001b[39m     \u001b[38;5;66;03m# instead of `if not ret`.\u001b[39;00m\n\u001b[32m   1155\u001b[39m     \u001b[38;5;66;03m# This will also catch `ret == False` as `False == 0`\u001b[39;00m\n\u001b[32m   1156\u001b[39m     \u001b[38;5;66;03m# but does not annoy the linters\u001b[39;00m\n\u001b[32m   1157\u001b[39m     \u001b[38;5;66;03m# https://docs.python.org/3/library/stdtypes.html#boolean-values\u001b[39;00m\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ret == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\knowledge_induced_noise\\Lib\\site-packages\\matplotlib\\animation.py:1469\u001b[39m, in \u001b[36mTimedAnimation._step\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1466\u001b[39m         \u001b[38;5;28mself\u001b[39m.event_source = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1467\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1469\u001b[39m \u001b[38;5;28mself\u001b[39m.event_source.interval = \u001b[38;5;28mself\u001b[39m._interval\n\u001b[32m   1470\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'interval'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'IPythonKernel' object has no attribute 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\backend_bases.py:1226\u001b[0m, in \u001b[0;36mTimerBase._on_timer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03mRuns all function that have been registered as callbacks. Functions\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;124;03mcan return False (or 0) if they should not be called any more. If there\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;124;03mare no callbacks, the timer is automatically stopped.\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m-> 1226\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;66;03m# docstring above explains why we use `if ret == 0` here,\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;66;03m# instead of `if not ret`.\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;66;03m# This will also catch `ret == False` as `False == 0`\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;66;03m# but does not annoy the linters\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;66;03m# https://docs.python.org/3/library/stdtypes.html#boolean-values\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\animation.py:1426\u001b[0m, in \u001b[0;36mTimedAnimation._step\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handler for getting events.\"\"\"\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;66;03m# Extends the _step() method for the Animation class.  If\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# Animation._step signals that it reached the end and we want to\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# repeat, we refresh the frame sequence and return True. If\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;66;03m# _repeat_delay is set, change the event_source's interval to our loop\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;66;03m# delay and set the callback to one which will then set the interval\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;66;03m# back.\u001b[39;00m\n\u001b[1;32m-> 1426\u001b[0m still_going \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_step(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m still_going:\n\u001b[0;32m   1428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repeat:\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;66;03m# Restart the draw loop\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\animation.py:1119\u001b[0m, in \u001b[0;36mAnimation._step\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1118\u001b[0m     framedata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_seq)\n\u001b[1;32m-> 1119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_next_frame(framedata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blit)\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\animation.py:1138\u001b[0m, in \u001b[0;36mAnimation._draw_next_frame\u001b[1;34m(self, framedata, blit)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_draw_next_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m, framedata, blit):\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;66;03m# Breaks down the drawing of the next frame into steps of pre- and\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;66;03m# post- draw, as well as the drawing of the frame itself.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_draw(framedata, blit)\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_frame(framedata)\n\u001b[0;32m   1139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_draw(framedata, blit)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\animation.py:1767\u001b[0m, in \u001b[0;36mFuncAnimation._draw_frame\u001b[1;34m(self, framedata)\u001b[0m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_count:]\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# Call the func with framedata and args. If blitting is desired,\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# func needs to return a sequence of any artists that were modified.\u001b[39;00m\n\u001b[1;32m-> 1767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drawn_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(framedata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blit:\n\u001b[0;32m   1771\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe animation function must return a sequence \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1772\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof Artist objects.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 185\u001b[0m, in \u001b[0;36mupdate_plot\u001b[1;34m(frame_number)\u001b[0m\n\u001b[0;32m    183\u001b[0m out\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    184\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m--> 185\u001b[0m exit()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\autocall.py:70\u001b[0m, in \u001b[0;36mZMQExitAutocall.__call__\u001b[1;34m(self, keep_kernel)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keep_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ip\u001b[38;5;241m.\u001b[39mkeepkernel_on_exit \u001b[38;5;241m=\u001b[39m keep_kernel\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ip\u001b[38;5;241m.\u001b[39mask_exit()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py:522\u001b[0m, in \u001b[0;36mZMQInteractiveShell.ask_exit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_exit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    521\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Engage the exit actions.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_now \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeepkernel_on_exit\n\u001b[0;32m    523\u001b[0m     payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    524\u001b[0m         source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_exit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m         keepkernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeepkernel_on_exit,\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload_manager\u001b[38;5;241m.\u001b[39mwrite_payload(payload)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:729\u001b[0m, in \u001b[0;36mTraitType.__set__\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m trait is read-only.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset(obj, value)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:718\u001b[0m, in \u001b[0;36mTraitType.set\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    714\u001b[0m     silent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# we explicitly compare silent to True just in case the equality\u001b[39;00m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# comparison above returns something other than True/False\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_notify_trait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, old_value, new_value)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1501\u001b[0m, in \u001b[0;36mHasTraits._notify_trait\u001b[1;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_notify_trait\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, old_value, new_value):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_change(\n\u001b[0;32m   1502\u001b[0m         Bunch(\n\u001b[0;32m   1503\u001b[0m             name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1504\u001b[0m             old\u001b[38;5;241m=\u001b[39mold_value,\n\u001b[0;32m   1505\u001b[0m             new\u001b[38;5;241m=\u001b[39mnew_value,\n\u001b[0;32m   1506\u001b[0m             owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1507\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1508\u001b[0m         )\n\u001b[0;32m   1509\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1513\u001b[0m, in \u001b[0;36mHasTraits.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotify_change\u001b[39m(\u001b[38;5;28mself\u001b[39m, change):\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Notify observers of a change event\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notify_observers(change)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1560\u001b[0m, in \u001b[0;36mHasTraits._notify_observers\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, EventHandler) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1558\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, c\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m-> 1560\u001b[0m c(event)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py:464\u001b[0m, in \u001b[0;36mZMQInteractiveShell._update_exit_now\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    462\u001b[0m exit_hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39meventloop, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exit_hook:\n\u001b[1;32m--> 464\u001b[0m     exit_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\eventloops.py:154\u001b[0m, in \u001b[0;36mloop_qt_exit\u001b[1;34m(kernel)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;129m@loop_qt4\u001b[39m\u001b[38;5;241m.\u001b[39mexit\n\u001b[0;32m    152\u001b[0m \u001b[38;5;129m@loop_qt5\u001b[39m\u001b[38;5;241m.\u001b[39mexit\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_qt_exit\u001b[39m(kernel):\n\u001b[1;32m--> 154\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39mexit()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'IPythonKernel' object has no attribute 'app'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model_yolo = YOLO('yolov8m-pose.pt')\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "output_file = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Lists to store tracked keypoint positions\n",
    "trackpoint1 = []\n",
    "trackpoint2 = []\n",
    "trackpoint3 = []\n",
    "\n",
    "# Colors for each keypoint (in BGR format)\n",
    "color1 = (255, 0, 0)    # Blue\n",
    "color2 = (0, 255, 0)    # Green\n",
    "color3 = (0, 0, 255)    # Red\n",
    "\n",
    "# Initialize variables for angle threshold tracking\n",
    "angle_threshold = 90\n",
    "below_threshold_count = 0\n",
    "prev_angle = None\n",
    "\n",
    "# Set up the matplotlib figure and subplots for real-time plotting (vertically stacked)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))  # Three subplots for three points\n",
    "\n",
    "# Plot lines for Point1\n",
    "lines1_x, = axes[0].plot([], [], 'b', label=' Tracking Wrist X Coordinate')\n",
    "lines1_y, = axes[0].plot([], [], 'c', label='Tracking Wrist Y Coordinate')\n",
    "\n",
    "# Plot lines for Point2\n",
    "lines2_x, = axes[1].plot([], [], 'g', label='Tracking Elbow  X Coordinate')\n",
    "lines2_y, = axes[1].plot([], [], 'm', label='Tracking Elbow Y Coordinate')\n",
    "\n",
    "# Plot lines for Point3\n",
    "lines3_x, = axes[2].plot([], [], 'r', label='Tracking Shoulder  X Coordinate')\n",
    "lines3_y, = axes[2].plot([], [], 'y', label='Tracking Shoulder Y Coordinate')\n",
    "\n",
    "# Set up the plot axis limits for each subplot\n",
    "for ax in axes:\n",
    "    ax.set_xlim(0, 1700)  # Adjust based on expected number of steps\n",
    "    ax.set_ylim(0, frame_height)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "axes[0].set_title('Tracking Wrist Coordinates vs Time Steps')\n",
    "axes[1].set_title('Tracking Elbow Coordinates vs Time Steps')\n",
    "axes[2].set_title('Tracking Shoulder Coordinates vs Time Steps')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Initialize step counter\n",
    "step = 0\n",
    "\n",
    "def calculate_angle(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the absolute angle in degrees between two points.\n",
    "    \"\"\"\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_radians = math.atan2(delta_y, delta_x)\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "    return abs(angle_degrees)\n",
    "\n",
    "def update_plot(frame_number):\n",
    "    global step, below_threshold_count, prev_angle\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Reached end of video.\")\n",
    "        plt.close(fig)  # Close the plot when video ends\n",
    "        return\n",
    "\n",
    "    # Perform YOLO detection\n",
    "    results = model_yolo(frame, stream=False, show=False)\n",
    "    for result in results:\n",
    "        keypoints = result.keypoints.xy  # Keypoints object for pose outputs\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            continue\n",
    "        matrix = np.asarray(keypoints[0])\n",
    "\n",
    "        # Draw all keypoints on the frame\n",
    "        for point in matrix:\n",
    "            if not np.array_equal(point, [0, 0]):\n",
    "                cv2.circle(frame, (int(point[0]), int(point[1])), 3, (255, 255, 255), -1)  # White for all keypoints\n",
    "\n",
    "        # Ensure matrix has enough keypoints before accessing the desired keypoints\n",
    "        if len(matrix) > 16:\n",
    "            point1 = matrix[10]  # Example keypoint index for Point1\n",
    "            point2 = matrix[8]  # Example keypoint index for Point2\n",
    "            point3 = matrix[6]  # Example keypoint index for Point3\n",
    "\n",
    "            if not np.array_equal(point1, [0, 0]):\n",
    "                trackpoint1.append((step, point1[0], point1[1]))\n",
    "            if not np.array_equal(point2, [0, 0]):\n",
    "                trackpoint2.append((step, point2[0], point2[1]))\n",
    "            if not np.array_equal(point3, [0, 0]):\n",
    "                trackpoint3.append((step, point3[0], point3[1]))\n",
    "\n",
    "    # Draw colored dots and lines for each tracked keypoint\n",
    "    for idx, (track, color) in enumerate(zip([trackpoint1, trackpoint2, trackpoint3], [color1, color2, color3])):\n",
    "        for j in range(1, len(track)):\n",
    "            pt1 = (int(track[j-1][1]), int(track[j-1][2]))\n",
    "            pt2 = (int(track[j][1]), int(track[j][2]))\n",
    "            cv2.circle(frame, pt2, 3, color, -1)  # Draw dot\n",
    "            cv2.line(frame, pt1, pt2, color, 2)  # Draw line\n",
    "\n",
    "    # Calculate the absolute angle between two points (e.g., point1 and point2)\n",
    "    if len(trackpoint1) > 0 and len(trackpoint2) > 0:\n",
    "        x1, y1 = trackpoint1[-1][1], trackpoint1[-1][2]\n",
    "        x2, y2 = trackpoint2[-1][1], trackpoint2[-1][2]\n",
    "        angle = calculate_angle(x1, y1, x2, y2)\n",
    "\n",
    "        # Check for transition from high value to below threshold\n",
    "        if prev_angle is not None and prev_angle >= angle_threshold and angle < angle_threshold:\n",
    "            below_threshold_count += 1\n",
    "\n",
    "        # Update the previous angle\n",
    "        prev_angle = angle\n",
    "\n",
    "        # Display the angle and count on the frame\n",
    "        cv2.putText(frame, f\"Angle: {angle:.2f} degrees\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        #cv2.putText(frame, f\"Count: {below_threshold_count}\", (50, 100),\n",
    "                    #cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Save the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Update plots for each tracked point\n",
    "    if trackpoint1:\n",
    "        steps1, x_coords1, y_coords1 = zip(*trackpoint1)\n",
    "        lines1_x.set_data(steps1, x_coords1)\n",
    "        lines1_y.set_data(steps1, y_coords1)\n",
    "\n",
    "    if trackpoint2:\n",
    "        steps2, x_coords2, y_coords2 = zip(*trackpoint2)\n",
    "        lines2_x.set_data(steps2, x_coords2)\n",
    "        lines2_y.set_data(steps2, y_coords2)\n",
    "\n",
    "    if trackpoint3:\n",
    "        steps3, x_coords3, y_coords3 = zip(*trackpoint3)\n",
    "        lines3_x.set_data(steps3, x_coords3)\n",
    "        lines3_y.set_data(steps3, y_coords3)\n",
    "\n",
    "    # Redraw the plot\n",
    "    for ax in axes:\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "\n",
    "    # Display the frame with keypoints and connecting lines\n",
    "    resized_frame = cv2.resize(frame, (int(frame_width * 1.9), int(frame_height * 1.5)))\n",
    "    cv2.imshow('Video1', resized_frame)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        plt.close(fig)\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "# Create the animation\n",
    "#ani = FuncAnimation(fig, update_plot, frames=range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), interval=30, repeat=False)\n",
    "ani = FuncAnimation(fig, update_plot, interval=10)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "plt.savefig('final_plot.png')  # Save the figure as a PNG file\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf135af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e215a-dffb-4bbc-a9f9-fe71c1635755",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f512fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "# Load the YOLO model with segmentation capabilities\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Retrieve video properties: width, height, and frames per second\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer to save the output video with the specified properties\n",
    "out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))\n",
    "\n",
    "# Define the region where the ID change should occur (e.g., bottom-right quarter of the frame)\n",
    "region_x1, region_y1 = int(w * 0.75), int(h * 0.75)\n",
    "region_x2, region_y2 = int(w * 0.5), h\n",
    "\n",
    "# Define a mapping for changed IDs\n",
    "changed_ids = set()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Create an annotator object to draw on the frame\n",
    "    annotator = Annotator(im0, line_width=2)\n",
    "\n",
    "    # Perform object tracking on the current frame\n",
    "    results = model.track(im0, persist=True)\n",
    "\n",
    "    # Check if tracking IDs and masks are present in the results\n",
    "    if results[0].boxes.id is not None and results[0].masks is not None:\n",
    "        # Extract masks and tracking IDs\n",
    "        masks = results[0].masks.xy\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
    "\n",
    "        # Annotate each mask with its corresponding tracking ID and color\n",
    "        for mask, track_id, box in zip(masks, track_ids, boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "\n",
    "            # Check if the object is within the defined region\n",
    "            if region_x1 <= (x1 + x2) // 2 <= region_x2 and region_y1 <= (y1 + y2) // 2 <= region_y2:\n",
    "                changed_ids.add(track_id)\n",
    "\n",
    "            # Change the ID to \"washed\" if the ID is in the changed_ids set\n",
    "            display_id = \"washed\" if track_id in changed_ids else str(track_id)\n",
    "\n",
    "            annotator.seg_bbox(mask=mask, mask_color=colors(track_id, True), track_label=display_id)\n",
    "\n",
    "    # Draw the defined region on the frame\n",
    "    cv2.rectangle(im0, (region_x1, region_y1), (region_x2, region_y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(im0)\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"instance-segmentation-object-tracking\", im0)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video writer and capture objects, and close all OpenCV windows\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0374f-22cd-4a53-bdbc-9a7a31af8ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
